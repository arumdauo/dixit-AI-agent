{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPt06/yjKo4X1FCeOkpPbT+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arumdauo/dixit-AI-bot/blob/main/generate_blip_vit_descriptions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generates BLIP and ViT descriptions for Dixit cards"
      ],
      "metadata": {
        "id": "jqmg_X5oUyrN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4bw51zfUpuZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch pillow pandas"
      ],
      "metadata": {
        "id": "4jeAzw0MVI69",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import json\n",
        "import torch\n",
        "from transformers import (BlipProcessor, BlipForConditionalGeneration,\n",
        "                          Blip2Processor, Blip2ForConditionalGeneration,\n",
        "                          VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer)\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_config(config_path='/content/drive/MyDrive/Colab Notebooks/dixit/config_generate_blip_vit_descriptions.json'):\n",
        "    with open(config_path, 'r') as config_file:\n",
        "        config = json.load(config_file)\n",
        "    return config\n",
        "\n",
        "def load_models():\n",
        "    blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "    blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(device)\n",
        "\n",
        "    vit_model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\").to(device)\n",
        "    vit_feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "    vit_tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "\n",
        "    blip2_processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
        "    blip2_model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\").to(device)\n",
        "\n",
        "    return (blip_processor, blip_model, vit_model, vit_feature_extractor, vit_tokenizer, blip2_processor, blip2_model)\n",
        "\n",
        "(blip_processor, blip_model, vit_model, vit_feature_extractor, vit_tokenizer, blip2_processor, blip2_model) = load_models()\n",
        "\n",
        "def generate_descriptions(image_path,\n",
        "                          blip_max_tokens=30, blip_temperature=0.9, blip_top_p=0.95,\n",
        "                          vit_max_length=50, vit_num_beams=5,\n",
        "                          blip2_max_tokens=30, blip2_temperature=0.9):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    blip_inputs = blip_processor(images=image, return_tensors=\"pt\").to(device)\n",
        "    blip_outputs = blip_model.generate(\n",
        "        **blip_inputs,\n",
        "        max_new_tokens=blip_max_tokens,\n",
        "        do_sample=True,\n",
        "        temperature=blip_temperature,\n",
        "        top_p=blip_top_p\n",
        "    )\n",
        "    blip_desc = blip_processor.decode(blip_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    vit_pixel_values = vit_feature_extractor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
        "    vit_inputs = vit_feature_extractor(images=image, return_tensors=\"pt\")\n",
        "    attention_mask = torch.ones_like(vit_inputs.pixel_values[:,:1])\n",
        "    vit_output_ids = vit_model.generate(\n",
        "        vit_inputs.pixel_values.to(device),\n",
        "        attention_mask=attention_mask.to(device),\n",
        "        max_new_tokens=vit_max_length,\n",
        "        num_beams=vit_num_beams,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "    vit_desc = vit_tokenizer.decode(vit_output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    blip2_inputs = blip2_processor(images=image, return_tensors=\"pt\").to(device)\n",
        "    blip2_outputs = blip2_model.generate(\n",
        "        **blip2_inputs,\n",
        "        max_new_tokens=blip2_max_tokens,\n",
        "        do_sample=True,\n",
        "        temperature=blip2_temperature\n",
        "    )\n",
        "    blip2_desc = blip2_processor.decode(blip2_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return blip_desc, vit_desc, blip2_desc\n",
        "\n",
        "def process_images(output_csv_path, image_folder,\n",
        "                   blip_max_tokens=30, blip_temperature=0.9, blip_top_p=0.95,\n",
        "                   vit_max_length=50, vit_num_beams=5,\n",
        "                   blip2_max_tokens=30, blip2_temperature=0.9):\n",
        "    result_data = []\n",
        "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png'))]\n",
        "\n",
        "    for image_name in image_files:\n",
        "        image_path = os.path.join(image_folder, image_name)\n",
        "\n",
        "        blip_desc, vit_desc, blip2_desc = generate_descriptions(\n",
        "            image_path,\n",
        "            blip_max_tokens=blip_max_tokens, blip_temperature=blip_temperature, blip_top_p=blip_top_p,\n",
        "            vit_max_length=vit_max_length, vit_num_beams=vit_num_beams,\n",
        "            blip2_max_tokens=blip2_max_tokens, blip2_temperature=blip2_temperature\n",
        "        )\n",
        "\n",
        "        result_data.append({\n",
        "            \"Image\": image_name,\n",
        "            \"BLIP\": blip_desc,\n",
        "            \"ViT\": vit_desc,\n",
        "            \"BLIP-2\": blip2_desc\n",
        "        })\n",
        "\n",
        "    os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n",
        "    df = pd.DataFrame(result_data)\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "config = load_config()\n",
        "\n",
        "process_images(\n",
        "    config[\"output_csv_path\"],\n",
        "    config[\"image_folder\"],\n",
        "    blip_max_tokens=config.get(\"blip_max_tokens\", 30),\n",
        "    blip_temperature=config.get(\"blip_temperature\", 0.9),\n",
        "    blip_top_p=config.get(\"blip_top_p\", 0.95),\n",
        "    vit_max_length=config.get(\"vit_max_length\", 50),\n",
        "    vit_num_beams=config.get(\"vit_num_beams\", 5),\n",
        "    blip2_max_tokens=config.get(\"blip2_max_tokens\", 30),\n",
        "    blip2_temperature=config.get(\"blip2_temperature\", 0.9)\n",
        ")\n",
        "\n",
        "del blip_processor, blip_model, vit_model, vit_feature_extractor, vit_tokenizer, blip2_processor, blip2_model\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "gGbPaWqxVR-K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
